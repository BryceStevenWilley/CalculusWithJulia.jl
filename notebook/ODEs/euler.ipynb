{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Euler's method"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using CalculusWithJulia\nusing CalculusWithJulia.WeaveSupport\nusing Plots\nnothing"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider the differential equation:\n\n$$~\ny'(x) = y(x) \\cdot  x, \\quad y(1)=1,\n~$$\n\nwhich can be solved with `SymPy`:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using CalculusWithJulia   # loads `SymPy`, `Roots`\nusing Plots\n@vars x y\nu = SymFunction(\"u\")\nx0, y0 = 1, 1\nF(y,x) = y*x\n\ndsolve(u'(x) - F(u(x), x))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the given initial condition, the solution becomes:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "out = dsolve(u'(x) - F(u(x),x), u(x), ics=(u, x0, y0))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting this solution over the slope field"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "p = plot(legend=false)\nvectorfieldplot!((x,y) -> [1, F(x,y)], xlims=(0, 2.5), ylims=(0, 10))\nplot!(rhs(out),  linewidth=5)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "we see that the vectors that are drawn seem to be tangent to the graph\nof the solution. This is no coincidence, the tangent lines to integral\ncurves are in the direction of the slope field.\n\n\nWhat if the graph of the solution were not there, could we use this\nfact to *approximately* reconstruct the solution?\n\nThat is, if we stitched together pieces of the slope field, would we\nget a curve that was close to the actual answer?"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "## {{{euler_graph}}}\n\nfig_size = (600, 400)\nfunction make_euler_graph(n)\n    x, y = symbols(\"x, y\")\n    F(y,x) = y*x\n    x0, y0 = 1, 1\n\n    h = (2-1)/5\n    xs = zeros(n+1)\n    ys = zeros(n+1)\n    xs[1] = x0   # index is off by 1\n    ys[1] = y0\n    for i in 1:n\n        xs[i + 1] = xs[i] + h\n        ys[i + 1] = ys[i] + h * F(ys[i], xs[i])\n    end\n\n\tp = plot(legend=false)\n    vectorfieldplot!((x,y) -> [1, F(y,x)], xlims=(1,2), ylims=(0,6))\n\n    ## Add Euler soln\n    plot!(p, xs, ys, linewidth=5)\n    scatter!(p, xs, ys)\n\n    ## add function\n    u = SymFunction(\"u\")\n    out = dsolve(u'(x) - F(u(x), x), u(x), ics=(u, x0, y0))\n    plot!(p, rhs(out), x0, xs[end], linewidth=5)\n\n    p\nend\n\n\n\n\nn = 5\nanim = @animate for i=1:n\n    make_euler_graph(i)\nend\n\nimgfile = tempname() * \".gif\"\ngif(anim, imgfile, fps = 1)\n\n\ncaption = \"\"\"\nIllustration of a function stitching together slope field lines to\napproximate the answer to an initial-value problem. The other function drawn is the actual solution.\n\"\"\"\n\nImageFile(imgfile, caption)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The illustration suggests the answer is yes, let's see. The solution\nis drawn over $x$ values $1$ to $2$. Let's try piecing together $5$\npieces between $1$ and $2$ and see what we have.\n\nThe slope-field vectors are *scaled* versions of the vector `[1, F(y,x)]`. The `1`\nis the part in the direction of the $x$ axis, so here we would like\nthat to be $0.2$ (which is $(2-1)/5$. So our vectors would be `0.2 *\n[1, F(y,x)]`. To allow for generality, we use `h` in place of the\nspecific value $0.2$.\n\nThen our first pieces would be the line connecting $(x_0,y_0)$ to\n\n$$~\n\\langle x_0, y_0 \\rangle + h \\cdot \\langle 1, F(y_0, x_0) \\rangle.\n~$$\n\nThe above uses vector notation to add the piece scaled by $h$ to the\nstarting point. Rather than continue with that notation, we will use\nsubscripts. Let $x_1$, $y_1$ be the postion of the tip of the\nvector. Then we have:\n\n$$~\nx_1 = x_0 + h, \\quad y_1 = y_0 + h F(y_0, x_0).\n~$$\n\nWith this notation, it is easy to see what comes next:\n\n$$~\nx_2 = x_1 + h, \\quad y_2 = y_1 + h F(y_1, x_1).\n~$$\n\nWe just shifted the indices forward by $1$. But graphically what is\nthis? It takes the tip of the first part of our \"stitched\" together\nsolution, finds the slope filed there (`[1, F(y,x)]`) and then uses\nthis direction to stitch together one more piece.\n\nClearly, we can repeat. The $n$th piece will end at:\n\n$$~\nx_{n+1} = x_n + h, \\quad y_{n+1} = y_n + h F(y_n, x_n).\n~$$\n\nFor our example, we can do some numerics. We want $h=0.2$ and $5$\npieces, so values of $y$ at $x_0=1, x_1=1.2, x_2=1.4, x_3=1.6,\nx_4=1.8,$ and $x_5=2$.\n\nBelow we do this in a loop. We have to be a bit careful, as in `Julia`\nthe vector of zeros we create to store our answers begins indexing at\n$1$, and not $0$."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "n=5\nh = (2-1)/n\nxs = zeros(n+1)\nys = zeros(n+1)\nxs[1] = x0   # index is off by 1\nys[1] = y0\nfor i in 1:n\n  xs[i + 1] = xs[i] + h\n  ys[i + 1] = ys[i] + h * F(ys[i], xs[i])\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "So how did we do? Let's look graphically:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(exp(-1/2)*exp(x^2/2), x0, 2)\nplot!(xs, ys)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not bad. We wouldn't expect this to be exact - due to the concavity\nof the solution, each step is an underestimate. However, we see it is\nan okay approximation and would likely be better with a smaller $h$. A\ntopic we pursue in just a bit.\n\nRather than type in the above command each time, we wrap it all up in\na function.  The inputs are $n$, $a=x_0$, $b=x_n$, $y_0$, and, most\nimportantly, $F$. The output is massaged into a function through a\ncall to `linterp`, rather than two vectors. The `linterp` function we define below just\nfinds a function that linearly interpolates between the points and is\n`NaN` outside of the range of the $x$ values:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function linterp(xs, ys)\n    function(x)\n        ((x < xs[1]) || (x > xs[end])) && return NaN\n        for i in 1:(length(xs) - 1)\n            if xs[i] <= x < xs[i+1]\n                l = (x-xs[i]) / (xs[i+1] - xs[i])\n                return (1-l) * ys[i] + l * ys[i+1]\n            end\n        end\n        ys[end]\n    end\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "With that, here is our function to find an approximate solution to $y'=F(y,x)$ with initial condition:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function euler(F, x0, xn, y0, n)\n  h = (xn - x0)/n\n  xs = zeros(n+1)\n  ys = zeros(n+1)\n  xs[1] = x0\n  ys[1] = y0\n  for i in 1:n\n    xs[i + 1] = xs[i] + h\n    ys[i + 1] = ys[i] + h * F(ys[i], xs[i])\n  end\n  linterp(xs, ys)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "With `euler`, it becomes easy to explore different values.\n\nFor example, we thought the solution would look better with a smaller $h$ (or larger $n$). Instead of $n=5$, let's try $n=50$:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "u = euler(F, 1, 2, 1, 50)\nplot(exp(-1/2)*exp(x^2/2), x0, 2)\nplot!(u, x0, 2)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is more work for the computer, but not for us, and clearly a much better approximation to the actual answer is found.\n\n\n## The Euler method"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "imgfile =\"figures/euler.png\"\ncaption = \"\"\"Figure from first publication of Euler's method. From [Gander and Wanner](http://www.unige.ch/~gander/Preprints/Ritz.pdf).\"\"\"\n\nImageFile(imgfile, caption)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The name of our function reflects the [mathematician](https://en.wikipedia.org/wiki/Leonhard_Euler) associated with the iteration:\n\n$$~\nx_{n+1} = x_n + h, \\quad y_{n+1} = y_n + h \\cdot F(y_n, x_n),\n~$$\n\nto approximate a solution to the first-order, ordinary differential\nequation with initial values: $y'(x) = F(y,x)$.\n\n\n[The Euler method](https://en.wikipedia.org/wiki/Euler_method) uses\nlinearization. Each \"step\" is just an approximation of the function\nvalue $y(x_{n+1})$ with the value from the tangent line tangent to the\npoint $(x_n, y_n)$.\n\n\nEach step introduces an error. The error in one step is known as the\n*local truncation error* and can be shown to be about equal to $1/2\n\\cdot h^2 \\cdot f''(x_{n})$ assuming $y$ has 3 or more derivatives.\n\nThe total error, or more commonly, *global truncation error*, is the\nerror between the actual answer and the approximate answer at the end\nof the process. It reflects an accumulation of these local errors. This\nerror is *bounded* by a constant times $h$. Since it gets smaller as\n$h$ gets smaller in direct proportion, the Euler method is called\n*first order*.\n\nOther, somewhat more complicated, methods have global truncation errors that\ninvolve higher powers of $h$ - that is for the same size $h$, the\nerror is smaller. In analogy is the fact that Riemann sums have\nerror that depends on $h$, whereas other methods of approximating the\nintegral have smaller errors. For example, Simpson's rule had error\nrelated to $h^4$. So, the Euler method may not be employed if there\nis concern about total resources (time, computer, ...), it is\nimportant for theoretical purposes in a manner similar to the role of the Riemann\nintegral.\n\nIn the examples, we will see that for many problems the simple Euler\nmethod is satisfactory, but not always so. The task of numerically\nsolving differential equations is not a one-size-fits-all one. In the\nfollowing, a few different modifications are presented to the basic\nEuler method, but this just scratches the surface of the topic.\n\n## Examples\n\n##### Example\n\n\nConsider the initial value problem $y'(x) = x + y(x)$ with initial\ncondition $y(0)=1$. This problem can be solved exactly. Here we\napproximate over $[0,2]$ using Euler's method."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "F(y,x) = x + y\nx0, xn, y0 = 0, 2, 1\nf = euler(F, x0, xn, y0, 25)\nf(xn)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We graphically compare our approximate answer with the exact one:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(f, x0, xn)\nu = SymFunction(\"u\")\nout = dsolve(u'(x) - F(u(x),x), u(x), ics = (u, x0, y0))\nplot(rhs(out), x0, xn)\nplot!(f, x0, xn)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the graph it appears our value for `f(xn)` will underestimate the\nactual value of the solution slightly.\n\n##### Example\n\nThe equation $y'(x) = \\sin(x \\cdot y)$ is not separable, so need not have an\neasy solution. `SymPy` will return a power series *approximation*. Let's\nlook at comparing an approximate answer given by the Euler method and  to\nthat one returned by `SymPy`.\n\nFirst, the `SymPy` solution:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@vars x\nu = SymFunction(\"u\")\nF(y,x) = sin(x*y)\neqn = u'(x) - F(u(x), x)\nout = dsolve(eqn)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we assume $y(0) = 1$, we can continue:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "out = dsolve(eqn, u(x), ics=(u, 0, 1))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The approximate value given by the Euler method is"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "x0, xn, y0 = 0, 2, 1\n\np = plot(legend=false)\nvectorfieldplot!((x,y) -> [1, F(y,x)], xlims=(x0,xn), ylims=(0,5))\nplot!(rhs(out).removeO(),  linewidth=5)\n\nu = euler(F, x0, xn, y0, 10)\nplot!(u, linewidth=5)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the answer found from using a polynomial series matches that of Euler's method for a bit, but as time evolves, the approximate solution given by Euler's method more closely tracks the slope field.\n\n##### Example\n\n\nThe\n[Brachistochrone problem](http://www.unige.ch/~gander/Preprints/Ritz.pdf)\nwas posed by Johann Bernoulli in 1696. It asked for the curve between\ntwo points for which an object will fall faster along that curve than\nany other. For an example, a bead sliding on a wire will take  a certain amount of time to get from point $A$ to point $B$, the time depending on the shape of the wire. Which shape will take the least amount  of time?"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "imgfile = \"figures/bead-game.jpg\"\ncaption = \"\"\"\n\nA child's bead game. What shape wire will produce the shortest time for a bed to slide from a top to the bottom?\n\n\"\"\"\nImageFile(imgfile, caption)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restrict our attention to the $x$-$y$ plane, and consider a path,\nbetween the point $(0,A)$ and $(B,0)$. Let $y(x)$ be the distance from\n$A$, so $y(0)=0$ and at the end $y$ will be $A$.\n\n\n[Galileo](http://www-history.mcs.st-and.ac.uk/HistTopics/Brachistochrone.html)\nknew the straight line was not the curve, but incorrectly thought the\nanswer was a part of a circle."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "imgfile = \"figures/galileo.gif\"\ncaption = \"\"\"\nAs early as 1638, Galileo showed that an object falling along `AC` and then `CB` will fall faster than one traveling along `AB`, where `C` is on the arc of a circle.\nFrom the [History of Math Archive](http://www-history.mcs.st-and.ac.uk/HistTopics/Brachistochrone.html).\n\"\"\"\nImageFile(imgfile, caption)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This simulation also suggests that a curved path is better than the shorter straight one:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "##{{{brach_graph}}}\n\nfunction brach(f, x0, vx0, y0, vy0, dt, n)\n    m = 1\n    g = 9.8\n\n    axs = Float64[0]\n    ays = Float64[-g]\n    vxs = Float64[vx0]\n    vys = Float64[vy0]\n    xs = Float64[x0]\n    ys = Float64[y0]\n\n    for i in 1:n\n        x = xs[end]\n        vx = vxs[end]\n\n        ax = -f'(x) * (f''(x) * vx^2 + g) / (1 + f'(x)^2)\n        ay = f''(x) * vx^2 + f'(x) * ax\n\n        push!(axs, ax)\n        push!(ays, ay)\n\n        push!(vxs, vx + ax * dt)\n        push!(vys, vys[end] + ay * dt)\n        push!(xs, x       + vxs[end] * dt)# + (1/2) * ax * dt^2)\n        push!(ys, ys[end] + vys[end] * dt)# + (1/2) * ay * dt^2)\n    end\n\n    [xs ys vxs vys axs ays]\n\nend\n\n\nfs = [x -> 1 - x,\n      x -> (x-1)^2,\n      x -> 1 - sqrt(1 - (x-1)^2),\n      x ->  - (x-1)*(x+1),\n      x -> 3*(x-1)*(x-1/3)\n      ]\n\n\nMS = [brach(f, 1/100, 0, 1, 0, 1/100, 100) for f in fs]\n\n\nfunction make_brach_graph(n)\n\n    p = plot(xlim=(0,1), ylim=(-1/3, 1), legend=false)\n    for (i,f) in enumerate(fs)\n        plot!(f, 0, 1)\n        U = MS[i]\n        x = min(1.0, U[n,1])\n        scatter!(p, [x], [f(x)])\n    end\n    p\n\nend\n\n\n\nn = 4\nanim = @animate for i=[1,5,10,15,20,25,30,35,40,45,50,55,60]\n    make_brach_graph(i)\nend\n\nimgfile = tempname() * \".gif\"\ngif(anim, imgfile, fps = 1)\n\n\ncaption = \"\"\"\nThe race is on. An illustration of beads falling along a path, as can be seen, some paths are faster than others. The fastest path would follow a cycloid. See [Bensky and Moelter](https://pdfs.semanticscholar.org/66c1/4d8da6f2f5f2b93faf4deb77aafc7febb43a.pdf) for details on simulating a bead on a wire.\n\"\"\"\n\nImageFile(imgfile, caption)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the natural question is which path is best?  The solution can be\n[reduced](http://mathworld.wolfram.com/BrachistochroneProblem.html) to\nsolving this equation for a positive $c$:\n\n$$~\n1 + (y'(x))^2  = \\frac{c}{y}, \\quad c > 0.\n~$$\n\nReexpressing, this becomes:\n\n$$~\n\\frac{dy}{dx} = \\sqrt{\\frac{C-y}{y}}.\n~$$\n\nThis is a separable equation and can be solved, but even `SymPy` has\ntrouble with this integral. However, the result has been known to be a piece of a cycloid since the insightful\nJacob Bernoulli used an analogy from light bending to approach the problem. The answer is best described parametrically\nthrough:\n\n$$~\nx(u) = c\\cdot u - \\frac{c}{2}\\sin(2u), \\quad y(u) = \\frac{c}{2}( 1- \\cos(2u)), \\quad 0 \\leq u \\leq U.\n~$$\n\nThe values of $U$ and $c$ must satisfy $(x(U), y(U)) = (B, A)$.\n\n\nRather than pursue this, we will solve it numerically for a fixed\nvalue of $C$ over a fixed interval to see the shape.\n\n\nThe equation can be written in terms of $y'=F(y,x)$, where\n\n$$~\nF(y,x) = \\sqrt{\\frac{c-y}{y}}.\n~$$\n\nBut as $y_0 = 0$, we immediately would have a problem with the first step, as there would be division by $0$.\n\nThis says that for the optimal solution, the bead picks up speed by first sliding straight down before heading off towards $B$. That's great for the physics, but runs roughshod over our Euler method, as the first step has an infinity.\n\nFor this, we can try the *backwards Euler* method which uses the slope at $(x_{n+1}, y_{n+1})$, rather than $(x_n, y_n)$. The update step becomes:\n\n$$~\ny_{n+1} = y_n + h \\cdot F(y_{n+1}, x_{n+1}).\n~$$\n\nSeems innocuous, but the value we are trying to find, $y_{n+1}$, is\nnow on both sides of the equation, so is only *implicitly* defined. In\nthis code, we use the `find_zero` function from the `Roots` package. The\ncaveat is, this function needs a good initial guess, and the one we\nuse below need not be widely applicable."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function back_euler(F, x0, xn, y0, n)\n    h = (xn - x0)/n\n    xs = zeros(n+1)\n    ys = zeros(n+1)\n    xs[1] = x0\n    ys[1] = y0\n    for i in 1:n\n        xs[i + 1] = xs[i] + h\n        ## solve y[i+1] = y[i] + h * F(y[i+1], x[i+1])\n        ys[i + 1] = find_zero(y -> ys[i] + h * F(y, xs[i + 1]) - y, ys[i]+h)\n    end\n  linterp(xs, ys)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then have with $C=1$ over the interval $[0,1.2]$ the following:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "F(y, x; C=1) = sqrt(C/y - 1)\nx0, xn, y0 = 0, 1.2, 0\ncyc = back_euler(F, x0, xn, y0, 50)\nplot(x -> 1 - cyc(x), x0, xn)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember, $y$ is the displacement from the top, so it is\nnon-negative. Above we flipped the graph to make it look more like\nexpectation. In general, the trajectory may actually dip below the\nending point and come back up. The above won't see this, for as\nwritten $dy/dx \\geq 0$, which need not be the case, as the defining\nequation is in terms of $(dy/dx)^2$, so the derivative could have any\nsign.\n\n\n\n##### Example: Stiff equations\n\nThe Euler method is *convergent*, in that as $h$ goes to $0$, the\napproximate solution will converge to the actual answer. However, this\ndoes not say that for a fixed size $h$, the approximate value will be\ngood. For example, consider the differential equation $y'(x) =\n-5y$. This has solution $y(x)=y_0 e^{-5x}$. However, if we try the\nEuler method to get an answer over $[0,2]$ with $h=0.5$ we don't see\nthis:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "F(y,x) = -5y\nx0, xn, y0 = 0, 2, 1\nu = euler(F, x0, xn, y0, 4)     # n =4 => h = 2/4\nvectorfieldplot((x,y) -> [1,F(y,x)], xlims=(0, 2), ylims=(-5, 5))\nplot!(x -> y0 * exp(-5x), 0, 2, linewidth=5)\nplot!(u, 0, 2, linewidth=5)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we see is that the value of $h$ is too big to capture the decay\nscale of the solution. A smaller $h$, can do much better:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "u = euler(F, x0, xn, y0, 50)    # n=50 => h = 2/50\nplot(x -> y0 * exp(-5x), 0, 2)\nplot!(u, 0, 2)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an example of a\n[stiff equation](https://en.wikipedia.org/wiki/Stiff_equation). Such\nequations cause explicit methods like the Euler one problems, as small\n$h$s are needed to good results.\n\nThe implicit, backward Euler method does not have this issue, as we can see here:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "u = back_euler(F, x0, xn, y0, 4)     # n =4 => h = 2/4\nvectorfieldplot((x,y) -> [1,F(y,x)],  xlims=(0, 2), ylims=(-1, 1))\nplot!(x -> y0 * exp(-5x), 0, 2, linewidth=5)\nplot!(u, 0, 2, linewidth=5)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Example: The pendulum\n\n\nThe differential equation describing the simple pendulum is\n\n$$~\n\\theta''(t) = - \\frac{g}{l}\\sin(\\theta(t)).\n~$$\n\nThe typical approach to solving for $\\theta(t)$ is to use the small-angle approximation that $\\sin(x) \\approx x$, and then the differential equation simplifies to:\n$\\theta''(t) = -g/l \\cdot \\theta(t)$, which is easily solved.\n\nHere we try to get an answer numerically. However, the problem, as stated, is not a first order equation due to the $\\theta''(t)$ term. If we let $u(t) = \\theta(t)$ and $v(t) = \\theta'(t)$, then we get *two* coupled first order equations:\n\n$$~\nv'(t) = -g/l \\cdot \\sin(u(t)), \\quad u'(t) = v(t).\n~$$\n\nWe can try the Euler method here. A simple approach might be this iteration scheme:\n\n$$~\nx_{n+1} = x_n + h, \\quad u_{n+1} = u_n + h v_n, \\quad v_{n+1} = v_n - h \\cdot g/l \\cdot \\sin(u_n).\n~$$\n\nHere we need *two* initial conditions: one for the initial value\n$u(t_0)$ and the initial value of $u'(t_0)$. We have seen if we start at an angle $a$ and release the bal from rest, so $u'(0)=0$ we get a sinusoidal answer to the linearized model. What happens here? We let $a=1$, $L=5$ and $g=9.8$:\n\nWe write a function to solve this starting from $(x_0, y_0)$ and ending at $x_n$:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function euler2(x0, xn, y0, yp0, n; g=9.8, l = 5)\n  xs, us, vs = zeros(n+1), zeros(n+1), zeros(n+1)\n  xs[1], us[1], vs[1] = x0, y0, yp0\n  h = (xn - x0)/n\n  for i = 1:n\n    xs[i+1] = xs[i] + h\n\tus[i+1] = us[i] + h * vs[i]\n\tvs[i+1] = vs[i] + h * (-g / l) * sin(us[i])\n\tend\n\tlinterp(xs, us)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take $a = \\pi/4$ as the initial angle, then the approximate\nsolution should be $\\pi/4\\cos(\\sqrt{g/l}x)$ with period $T =\n2\\pi\\sqrt{l/g}$. We try first to plot then over 4 periods:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "l, g = 5, 9.8\nT = 2pi * sqrt(l/g)\nx0, xn, y0, yp0 = 0, 4T, pi/4, 0\nplot(euler2(x0, xn, y0, yp0, 20), 0, 4T)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Something looks terribly amiss. The issue is the step size, $h$, is\ntoo large to capture the oscillations. There are basically only $5$\nsteps to capture a full up and down motion. Instead, we try to get $20$ steps per period\nso $n$ must be not $20$, but $4 \\cdot 20 \\cdot T \\approx 360$. To this\ngraph, we add the approximate one:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(euler2(x0, xn, y0, yp0, 360), 0, 4T)\nplot!(x -> pi/4*cos(sqrt(g/l)*x), 0, 4T)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even now, we still see that something seems amiss, though the issue is\nnot as dramatic as before. The oscillatory nature of the pendulum is\nseen, but in the Euler solution, the amplitude grows, which would\nnecessarily mean energy is being put into the system.  A familiar\ninstance of a pendulum would be a child on a swing. Without pumping\nthe legs - putting energy in the system - the height of the swing's\narc will not grow.  Though we now have oscillatory motion, this growth\nindicates the solution is still not quite right. The issue is likely\ndue to each step mildly overcorrecting and resulting in an overall\ngrowth.  One of the questions pursues this a bit further.\n\n## Questions\n\n##### Question\n\nUse Euler's method with $n=5$ to approximate $u(1)$ where\n\n$$~\nu'(x) = x - u(x), \\quad u(0) = 1\n~$$"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "F(y,x) = x - y\nx0, xn, y0 = 0, 1, 1\nval = euler(F, x0, xn, y0, 5)(1)\nnumericq(val)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Question\n\nConsider the equation\n\n$$~\ny' = x \\cdot \\sin(y), \\quad y(0) = 1.\n~$$\n\nUse Euler's method with $n=50$ to find the value of $y(5)$."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "F(y, x) = x * sin(y)\nx0, xn, y0 = 0, 5, 1\nn = 50\nu = euler(F, x0, xn, y0, n)\nnumericq(u(xn))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Question\n\nConsider the ordinary differential equation\n\n$$~\n\\frac{dy}{dx} = 1 - 2\\frac{y}{x}, \\quad y(1) = 0.\n~$$\n\nUse Euler's method to solve for $y(2)$ when $n=50$."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "F(y, x) = 1 - 2y/x\nx0, xn, y0 = 1, 2, 0\nn = 50\nu = euler(F, x0, xn, y0, n)\nnumericq(u(xn))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Question\n\n\nConsider the ordinary differential equation\n\n$$~\n\\frac{dy}{dx} = \\frac{y \\cdot \\log(y)}{x}, \\quad y(2) = e.\n~$$\n\nUse Euler's method to solve for $y(3)$ when $n=25$."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "F(y, x) = y*log(y)/x\nx0, xn, y0 = 2, 3, exp(1)\nn = 25\nu = euler(F, x0, xn, y0, n)\nnumericq(u(xn))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Question\n\nConsider the first-order non-linear ODE\n\n$$~\ny' = y \\cdot (1-2x), \\quad y(0) = 1.\n~$$\n\nUse Euler's method with $n=50$ to approximate the solution $y$ over $[0,2]$.\n\nWhat is the value at $x=1/2$?"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "F(y, x) = y * (1-2x)\nx0, xn, y0 = 0, 2, 1\nn = 50\nu = euler(F, x0, xn, y0, n)\nnumericq(u(1/2))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the value at $x=3/2$?"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "numericq(u(3/2))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Question: The pendulum revisited.\n\nThe issue with the pendulum's solution growing in amplitude can be\naddressed using a modification to the Euler method attributed to\n[Cromer](http://astro.physics.ncsu.edu/urca/course_files/Lesson14/index.html). The\nfix is to replace the term `sin(us[i])` in the line `vs[i+1] = vs[i] + h * (-g / l) *\nsin(us[i])` of the `euler2` function with `sin(us[i+1])`, which uses the updated angular\nvelocity in the 2nd step in place of the value before the step.\n\nModify the `euler2` function to implement the Euler-Cromer method. What do you see?"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "choices = [\n\"The same as before - the amplitude grows\",\n\"The solution is identical to that of the approximation found by linearization of the sine term\",\n\"The solution has a constant amplitude, but its period is slightly *shorter* than that of the approximate solution found by linearization\",\n\"The solution has a constant amplitude, but its period is slightly *longer* than that of the approximate solution found by linearization\"]\nans = 4\nradioq(choices, ans, keep_order=true)"
      ],
      "metadata": {},
      "execution_count": null
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.5.0"
    },
    "kernelspec": {
      "name": "julia-1.5",
      "display_name": "Julia 1.5.0",
      "language": "julia"
    }
  },
  "nbformat": 4
}
